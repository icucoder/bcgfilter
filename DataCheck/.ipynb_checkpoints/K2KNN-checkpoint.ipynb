{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "093b7306-5dcc-42ab-a409-336674eac36b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 80\u001b[0m\n\u001b[1;32m     77\u001b[0m     label[i\u001b[38;5;241m*\u001b[39moneperson_nums:(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39moneperson_nums] \u001b[38;5;241m=\u001b[39m i\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# 数据对齐\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m Unite_model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/root/zqh/Save_Model/United_model_device.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcuda()\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     81\u001b[0m feature1, ans, feature2 \u001b[38;5;241m=\u001b[39m Unite_model(data\u001b[38;5;241m.\u001b[39mcuda())\n\u001b[1;32m     82\u001b[0m features \u001b[38;5;241m=\u001b[39m feature2\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/serialization.py:809\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    808\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m--> 809\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[1;32m    811\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/serialization.py:1172\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1170\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1171\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1172\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1174\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/serialization.py:1142\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1141\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1142\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/serialization.py:1116\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1112\u001b[0m storage \u001b[38;5;241m=\u001b[39m zip_file\u001b[38;5;241m.\u001b[39mget_storage_from_record(name, numel, torch\u001b[38;5;241m.\u001b[39mUntypedStorage)\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_untyped_storage\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m typed_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[0;32m-> 1116\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39m\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1117\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1118\u001b[0m     _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typed_storage\u001b[38;5;241m.\u001b[39m_data_ptr() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1121\u001b[0m     loaded_storages[key] \u001b[38;5;241m=\u001b[39m typed_storage\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/serialization.py:217\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 217\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    219\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/serialization.py:182\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_cuda_deserialize\u001b[39m(obj, location):\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m location\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 182\u001b[0m         device \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_cuda_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torch_load_uninitialized\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    184\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice(device):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/serialization.py:166\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    163\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_get_device_index(location, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m--> 166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttempting to deserialize object on a CUDA \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    167\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice but torch.cuda.is_available() is False. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    168\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you are running on a CPU-only machine, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    169\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    170\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto map your storages to the CPU.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    171\u001b[0m device_count \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from Toolkit import *\n",
    "import sys  \n",
    "sys.path.append('/root/zqh/filter_test')\n",
    "from FingerPrint_5_quick import *\n",
    "from United_model import *\n",
    "# 数据\n",
    "Pathlist = [\n",
    "    '/root/zqh/NewDataSet/BCG_ZQH2.pt',\n",
    "    '/root/zqh/NewDataSet/BCG_QJF1.pt',\n",
    "    '/root/zqh/NewDataSet/BCG_WCM1.pt',\n",
    "    '/root/zqh/NewDataSet/New_data_pa1.pt',\n",
    "    '/root/zqh/NewDataSet/New_data_pa2.pt',\n",
    "    '/root/zqh/NewDataSet/New_data_pa3.pt',\n",
    "    '/root/zqh/NewDataSet/New_data_pa5.pt',\n",
    "    '/root/zqh/NewDataSet/New_data_pa6.pt',\n",
    "    '/root/zqh/NewDataSet/New_data_pa7.pt',\n",
    "    '/root/zqh/NewDataSet/New_data_pa8.pt',\n",
    "    '/root/zqh/NewDataSet/New_data_pa9.pt',\n",
    "    '/root/zqh/NewDataSet/New_data_pa10.pt',\n",
    "    '/root/zqh/NewDataSet/New_data_pa11.pt', # poor\n",
    "    '/root/zqh/NewDataSet/New_data_pa12.pt',\n",
    "    '/root/zqh/NewDataSet/New_data_pa13.pt', # poor\n",
    "    '/root/zqh/NewDataSet/New_data_pa14.pt',\n",
    "    '/root/zqh/NewDataSet/New_data_pa15.pt', # poor\n",
    "    '/root/zqh/NewDataSet/New_data_pa16.pt', # poor\n",
    "    '/root/zqh/NewDataSet/New_data_pa17.pt',\n",
    "    '/root/zqh/NewDataSet/New_data_pa18.pt',\n",
    "    '/root/zqh/NewDataSet/New_data_pa19.pt',\n",
    "    '/root/zqh/NewDataSet/New_data_pa20.pt',\n",
    "    '/root/zqh/NewDataSet/New_data_pa21.pt',\n",
    "    '/root/zqh/NewDataSet/New_data_pa22.pt',\n",
    "    '/root/zqh/NewDataSet/New_data_pa23.pt',\n",
    "    '/root/zqh/NewDataSet/New_data_pa24.pt', # poor\n",
    "    '/root/zqh/NewDataSet/New_data_pa25.pt',\n",
    "    '/root/zqh/NewDataSet/New_data_pa26.pt',\n",
    "    '/root/zqh/NewDataSet/New_data_pa27.pt',\n",
    "    '/root/zqh/NewDataSet/New_data_pa28.pt',\n",
    "    '/root/zqh/NewDataSet/New_data_pa29.pt',\n",
    "    '/root/zqh/NewDataSet/New_data_pa30.pt', # poor\n",
    "    '/root/zqh/NewDataSet/New_data_pa31.pt',\n",
    "    '/root/zqh/NewDataSet/New_data_pa32.pt', # poor\n",
    "    '/root/zqh/NewDataSet/New_data_pa33.pt',\n",
    "    '/root/zqh/NewDataSet/New_data_pa34.pt',\n",
    "    '/root/zqh/NewDataSet/New_data_pa35.pt',\n",
    "    '/root/zqh/NewDataSet/New_data_pa36.pt',\n",
    "    '/root/zqh/NewDataSet/New_data_pa37.pt',\n",
    "    '/root/zqh/NewDataSet/New_data_pa38.pt',\n",
    "    '/root/zqh/NewDataSet/New_data_pa39.pt',\n",
    "    '/root/zqh/NewDataSet/New_data_pa40.pt',\n",
    "    '/root/zqh/BCGDataSet/modify_extract_Single_resolution_caoan615.pt',\n",
    "    '/root/zqh/BCGDataSet/modify_extract_Single_resolution_dj613.pt',\n",
    "    '/root/zqh/BCGDataSet/modify_extract_Single_resolution_dxt613.pt',\n",
    "    '/root/zqh/BCGDataSet/modify_extract_Single_resolution_ltm613.pt',\n",
    "    '/root/zqh/BCGDataSet/modify_extract_Single_resolution_qjf612.pt',\n",
    "    '/root/zqh/BCGDataSet/modify_extract_Single_resolution_rrx613.pt',\n",
    "    '/root/zqh/BCGDataSet/modify_extract_Single_resolution_sample1.pt',\n",
    "    '/root/zqh/BCGDataSet/modify_extract_Single_resolution_sjj612.pt',\n",
    "    '/root/zqh/BCGDataSet/modify_extract_Single_resolution_tt612.pt',\n",
    "    '/root/zqh/BCGDataSet/modify_extract_Single_resolution_wcm612.pt',\n",
    "    '/root/zqh/BCGDataSet/modify_extract_Single_resolution_wg613.pt',\n",
    "    '/root/zqh/BCGDataSet/modify_extract_Single_resolution_whd612.pt',\n",
    "    '/root/zqh/BCGDataSet/modify_extract_Single_resolution_wxy.pt',\n",
    "    '/root/zqh/BCGDataSet/modify_extract_Single_resolution_zj612.pt',\n",
    "    # '/root/zqh/BCGDataSet/modify_extract_Single_resolution_zqh1.pt',\n",
    "    '/root/zqh/BCGDataSet/modify_extract_Single_resolution_zzp612.pt',\n",
    "]\n",
    "oneperson_begin = 0\n",
    "oneperson_end = 30\n",
    "oneperson_nums = oneperson_end - oneperson_begin\n",
    "persons = len(Pathlist)\n",
    "data = get_ResUnet_data(Pathlist=Pathlist, oneperson_begin=oneperson_begin, oneperson_end=oneperson_end)[:,:,:].detach()\n",
    "label = torch.zeros(oneperson_nums*persons)\n",
    "for i in range(persons):\n",
    "    label[i*oneperson_nums:(i+1)*oneperson_nums] = i\n",
    "\n",
    "# 数据对齐\n",
    "# Unite_model = torch.load('/root/zqh/Save_Model/United_model_device.pth').cuda().eval()\n",
    "# feature1, ans, feature2 = Unite_model(data.cuda())\n",
    "# features = feature2\n",
    "# data = features\n",
    "# persons = int(data.shape[0]/oneperson_nums)\n",
    "# data = data.cuda()\n",
    "# # Metric_learning\n",
    "# Metric_model = torch.load('/root/zqh/Save_Model/train_Metric_Model_local.pth').cuda().eval()\n",
    "# length = data.shape[0]\n",
    "# output1 = Metric_model(data)  # 度量学习\n",
    "# data = output1\n",
    "\n",
    "def splitDataSet(data, label, persons, oneperson_nums): # 要求输入 shape: N x\n",
    "    X_train = data[0:20,:]\n",
    "    X_test = data[20:30,:]\n",
    "    y_train = label[0:20]\n",
    "    y_test = label[20:30]\n",
    "    for i in range(1,persons):\n",
    "        X_train = torch.cat([X_train, data[oneperson_nums*i:oneperson_nums*i+20,:]],dim=0)\n",
    "        X_test = torch.cat([X_test, data[oneperson_nums*i+20:oneperson_nums*i+30,:]],dim=0)\n",
    "        y_train = torch.cat([y_train, label[oneperson_nums*i:oneperson_nums*i+20]],dim=0)\n",
    "        y_test = torch.cat([y_test, label[oneperson_nums*i+20:oneperson_nums*i+30]],dim=0)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(data.cpu().squeeze(1), label, stratify=label, random_state=42)\n",
    "X_train, X_test, y_train, y_test = splitDataSet(data.cpu().squeeze(1), label, persons, oneperson_nums)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "def MyKNN(persons, X_train, X_test, y_train, y_test, k):\n",
    "    right = 0\n",
    "    oneperson_nums = 10\n",
    "    for i in range(X_test.shape[0]):\n",
    "        databegin = i//oneperson_nums*oneperson_nums\n",
    "        _,remainer,_,_ = train_test_split(X_test[databegin:databegin+oneperson_nums,:],\n",
    "                                          X_test[databegin:databegin+oneperson_nums,:],\n",
    "                                          test_size=(k-1)/oneperson_nums,\n",
    "                                          random_state=i)\n",
    "        Kset = torch.cat([X_test[i:i+1,:],remainer],dim=0)\n",
    "        record = torch.zeros(persons)\n",
    "        for j in range(k):\n",
    "            tmp = Kset[j].repeat(X_train.shape[0], 1)\n",
    "            distancelist = torch.sum((tmp-X_train)**2,dim=1)\n",
    "            distancelist = torch.cat([distancelist.unsqueeze(1), y_train.unsqueeze(1)],dim=1)\n",
    "            distancelist = distancelist.tolist()\n",
    "            distancelist = sorted(distancelist, key = lambda x:(x[0]))\n",
    "            record[int(distancelist[0][0])] += 1\n",
    "        maxvalue,maxindex = torch.max(record,dim=0)\n",
    "        if maxindex == y_test[i]:\n",
    "            right+=1\n",
    "    return right/y_test.shape[0]\n",
    "list = []\n",
    "k_range = 21\n",
    "for i in range(1, k_range):\n",
    "    ans = MyKNN(persons, X_train, X_test, y_train, y_test, k=i)\n",
    "    list.append(ans)\n",
    "arraylist = np.array(list)\n",
    "print(arraylist)\n",
    "ourans = np.array([0.9874, 0.9947, 0.9964, 1.0, 1.0,\n",
    "                   1.0, 1.0, 1.0, 1.0, 1.0,\n",
    "                   1.0, 1.0, 1.0, 1.0, 1.0,\n",
    "                   1.0, 1.0, 1.0, 1.0, 1.0,])\n",
    "print(ourans)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "plt.figure(figsize=(8, 6), dpi=100)\n",
    "x = torch.arange(1, k_range)\n",
    "plt.plot(x.numpy(), arraylist)\n",
    "plt.plot(x.numpy(), ourans)\n",
    "plt.ylim(0.95, 1.02)\n",
    "plt.xlabel('k', fontsize=20)\n",
    "plt.ylabel('ACC', fontsize=20)\n",
    "plt.show()\n",
    "# plt.savefig('learning_curve_picture.jpeg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
